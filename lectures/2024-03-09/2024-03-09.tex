%TEX root = 2024-03-09.tex
\documentclass[../../main/main.tex]{subfiles}
\begin{document}
\subsection{Lecture 4 - Master theorem}

\subsubsection{intro}
$T(n) = aT(\frac{n}{b}) + f(n)$
\begin{enumerate}
  \item $f(n) = n^{c + \epsilon}$ then $T(n) = \Theta(n^c)$ 
  \item $f(n) = n^{c}$  then $T(n) = O(n^{c}\logn)$
  \item $f(n) = n^{c - \epsilon}$, then $T(n) = \Omega(f(n)))$
\end{enumerate}

\subsubsection{inequality}
$T(n) = aT(\frac{n}{b}) + f(n)$
\begin{enumerate}
  \item $f(n) = O(n^{c + \epsilon})$ then $T(n) = O(n^c)$ 
  \item $f(n) = O(n^{c})$  then $T(n) = O(n^{c}\logn)$
  \item $f(n) = O(n^{c - \epsilon})$, then $T(n) = O(f(n))$
\end{enumerate}

\begin{remark}
  when $f(n) = \Theta(n)$, we will split the cases by checking c $>1$, c $= 1$ and c $<1$
\end{remark}
\newline

\pvocab{Proof}
when $f(n) = O(n)$
\begin{enumerate}
  \item 
    \begin{align*}
      T(n) &\le  aT(\frac{n}{b}) + f(n)\\
           &= a \cdot (T(\frac{n}{b^2})+ \cdot (\frac{n}{b})) + f(n) \\
           &=  \ldots \\
           &= a^{i}T(1) + a^{i-1} (\frac{n}{b^{i}}) + \ldots + kn\\
           &=  n^{c} + kn\sum^{\log_b(n)-1}_{i=0}(\frac{a}{b})^{i} && \texttt{case 1: $c > 1$} \\
           &= n^{c} + kn \cdot  \frac{(\frac{a}{b})^{\log_bn} - 1}{\frac{a}{b}-1} \\
           &\le n^{c} + kn \cdot  \frac{(\frac{a}{b})^{\log_bn} }{\frac{a}{b}-1} \\
           &=  n^{c} + k\cdot \frac{n^{\log_ba}}{\frac{a}{b}-1} \\
           &=  O(n^{c}) \\
    .\end{align*}
  \item 
\begin{align*} 
      T(n) &\le  aT(\frac{n}{b}) + f(n)\\
           &=  n + kn\sum^{\log_b(n)-1}_{i=0}(\frac{a}{b})^{i} && \texttt{case 2: $c = 1$} \\
           &=  n + kn \cdot (\log_bn -1) \\
           &=  O(n\log n)\\
.\end{align*}
\item
  \begin{align*}
       T(n) &\le  aT(\frac{n}{b}) + f(n)\\
           &=  n^{c} + kn\sum^{\log_b(n)-1}_{i=0}(\frac{a}{b})^{i} && \texttt{case 3: $c < 1$} \\
           &=  n^{c} + kn\cdot O(1)&&\texttt{decreasing geometric series} \\
           &= O(n) \\
  .\end{align*}
\end{enumerate}

\subsection{Lecture 5 - Randomized algorithms}
\begin{exercise}
  \begin{align*}
    S= \sum^{\infty}_{i=1} i(1-p)^{i-1} &= \sum^{\infty}_{j=0} (j+1)(k)^{j}\\
    kS &=    \sum^{\infty}_{j=1} (j+1)(k)^{j} && (1)\\
    S-kS &= 1+ k + k^{2} + k^3 + \ldots = \frac{1}{1-k} && (2)\\
    S &=  \frac{1}{(1-k)^2}\\
  .\end{align*}
\end{exercise}
\begin{exercise}[Coupon collector]
  \begin{align*}
    P(i) &=  \frac{n-i}{n}\\
    E[x_i] &= \frac{1}{P(i)} \\
    E[X]&= \sum^{n-1}_{i=1}  E[x_i]  \\
    &= n \sum^{n}_{i=1} \frac{1}{i} \\
    &= \Theta(n \log n) \\
  .\end{align*}
\end{exercise}
\begin{enumerate}
  \item hiring problem
  \item birthday paradox
  \item generate random permutation (with proof)
\end{enumerate}
\subsection{Lecture 6 - Quick Sort}
\subsubsection{Intro to algo}
\begin{algorithm}[H]
  \floatname{algorithm}{Algorithm}
  \algrenewcommand\algorithmicrequire{\textbf{Input: }}
  \algrenewcommand\algorithmicensure{\textbf{Output: }}
  \caption{Quicksort}\label{alg:}
  \begin{algorithmic}[1]
    \Require $A,p,q,r$
    \Ensure $1$
    \If{$p \ge r$}
    \State{\texttt{return}}
    \EndIf
    \State $q = \Call{partition}{A,p,r}$
    \State $\Call{quicksort}{A,p,q-1}$
    \State $\Call{quicksort}{A,q+1, r}$
    \State \textbf{return} $state$
  \end{algorithmic}
\end{algorithm}
% \usepackage{algorithm,algorithmicx,algpseudocode}
\begin{algorithm}[H]
  \floatname{algorithm}{Algorithm}
  \algrenewcommand\algorithmicrequire{\textbf{Input: }}
  \algrenewcommand\algorithmicensure{\textbf{Output: }}
  \caption{Partition}\label{alg:}
  \begin{algorithmic}[1]
    \Require $A,p,r$
    \Ensure $q$
    \State $i \gets p-1$
    \For{$j \gets p$ to $r-1$}
    \If{$A[j] \le x$}
    \State $i \gets i+1$
    \State $\Call{swap}{A[i], A[j]}$
    \EndIf
    \EndFor
    \State \textbf{return} $i$
  \end{algorithmic}
\end{algorithm}

\subsubsection{Run time analysis}
\begin{enumerate}
  \item best case: $O(\log n)$
  \item worse case: $O(n^2)$
\end{enumerate}

\pvocab{Average run-time of quicksort.}
To attain average case, randomly select the pivot. Let $p(x_{i,j})$ be the probability that $z_i$ and $z_j$ are compared
\begin{align*}
  p(x_{i,j}) &= \frac{1}{j-i+1} \\
  E[X]&= \sum^{n}_{i=1} 2\cdot p(x_{i,j}) && \texttt{$z_{i}$ and $z_j$ are symmetric}\\ 
  &= O(n \log n) \\
.\end{align*}
\begin{exercise}[k-smallest element in union of two sorted lists]
  
\end{exercise}
\end{document}

